{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2NjlaDPUoG76VaQfh8FPF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rallm/IUST-DL-Fall2025/blob/main/HW5/helper/hw5_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q31_SZeuaR5C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Layer 1: RNN(input=64, hidden=32)\n",
        "        self.layer1 = nn.RNN(input_size=64, hidden_size=32, num_layers=1, batch_first=True, nonlinearity='tanh')\n",
        "\n",
        "        # Layer 2: RNN(input=32, hidden=64)\n",
        "        self.layer2 = nn.RNN(input_size=32, hidden_size=64, num_layers=1, batch_first=True, nonlinearity='tanh')\n",
        "\n",
        "        # Layer 3: Linear(64, 512)\n",
        "        self.layer3 = nn.Linear(64, 512)\n",
        "\n",
        "        # Layer 4: Linear(512, 10)\n",
        "        self.layer4 = nn.Linear(512, 10)\n",
        "\n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part A: Output Shapes & Parameters ---\n",
        "def count_params(layer):\n",
        "    weights = sum(p.numel() for name, p in layer.named_parameters() if 'weight' in name)\n",
        "    biases = sum(p.numel() for name, p in layer.named_parameters() if 'bias' in name)\n",
        "    return weights, biases\n",
        "\n",
        "print(\"--- Part A: Parameters ---\")\n",
        "l1_w, l1_b = count_params(model.layer1)\n",
        "print(f\"Layer 1 (RNN): Weights={l1_w}, Biases={l1_b}, Total={l1_w + l1_b}\")\n",
        "\n",
        "l2_w, l2_b = count_params(model.layer2)\n",
        "print(f\"Layer 2 (RNN): Weights={l2_w}, Biases={l2_b}, Total={l2_w + l2_b}\")\n",
        "\n",
        "l3_w = model.layer3.weight.numel()\n",
        "l3_b = model.layer3.bias.numel()\n",
        "print(f\"Layer 3 (Linear): Weights={l3_w}, Biases={l3_b}, Total={l3_w + l3_b}\")\n",
        "\n",
        "l4_w = model.layer4.weight.numel()\n",
        "l4_b = model.layer4.bias.numel()\n",
        "print(f\"Layer 4 (Linear): Weights={l4_w}, Biases={l4_b}, Total={l4_w + l4_b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjQoIBATaeDJ",
        "outputId": "8c6f41e8-ac33-4072-b343-7b5762253967"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Part A: Parameters ---\n",
            "Layer 1 (RNN): Weights=3072, Biases=64, Total=3136\n",
            "Layer 2 (RNN): Weights=6144, Biases=128, Total=6272\n",
            "Layer 3 (Linear): Weights=32768, Biases=512, Total=33280\n",
            "Layer 4 (Linear): Weights=5120, Biases=10, Total=5130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part B: FLOPs Estimation ---\n",
        "# Formula for RNN Cell (per step):\n",
        "# Muls = H * D (W_ih) + H * H (W_hh)\n",
        "# Adds = H * D (W_ih) + H * H (W_hh) + H (bias_ih) + H (bias_hh)\n",
        "# Total Ops approx = 2 * H * (D + H) + Biases (ignoring activation cost for simplicity or counting as 1)\n",
        "# Here we calculate Muls and Adds specifically.\n",
        "\n",
        "def calculate_rnn_flops(seq_len, input_size, hidden_size):\n",
        "    # Matrix-Vector Multiplications: (H, D)x(D, 1) and (H, H)x(H, 1)\n",
        "    muls = (hidden_size * input_size) + (hidden_size * hidden_size)\n",
        "    # Additions: Matrix products accumulation + biases + combining states\n",
        "    adds = (hidden_size * input_size) + (hidden_size * hidden_size) + 2 * hidden_size\n",
        "\n",
        "    total_ops_per_step = muls + adds\n",
        "    return total_ops_per_step * seq_len\n",
        "\n",
        "def calculate_linear_flops(input_size, output_size):\n",
        "    muls = input_size * output_size\n",
        "    adds = input_size * output_size + output_size # +bias\n",
        "    return muls + adds\n",
        "\n",
        "print(\"\\n--- Part B: FLOPs ---\")\n",
        "seq_len = 50\n",
        "l1_flops = calculate_rnn_flops(seq_len, 64, 32)\n",
        "l2_flops = calculate_rnn_flops(seq_len, 32, 64)\n",
        "# Assuming Linear layers are applied only to the final hidden state (Many-to-One)\n",
        "l3_flops = calculate_linear_flops(64, 512)\n",
        "l4_flops = calculate_linear_flops(512, 10)\n",
        "\n",
        "print(f\"L1 FLOPs: {l1_flops}\")\n",
        "print(f\"L2 FLOPs: {l2_flops}\")\n",
        "print(f\"L3 FLOPs: {l3_flops}\")\n",
        "print(f\"L4 FLOPs: {l4_flops}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoRcD7QhahAR",
        "outputId": "e7d0a6a6-b605-497f-e321-559cc579d6a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part B: FLOPs ---\n",
            "L1 FLOPs: 310400\n",
            "L2 FLOPs: 620800\n",
            "L3 FLOPs: 66048\n",
            "L4 FLOPs: 10250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4b_o8JwlCH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}