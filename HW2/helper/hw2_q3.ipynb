{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfzZB6g+FDKN+AxfdYeVwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rallm/IUST-DL-Fall2025/blob/main/HW2/helper/hw2_q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TpHNbjqXM_cz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set print options for better readability\n",
        "np.set_printoptions(precision=4, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W1: Weights from input (3 features) to hidden (4 neurons)\n",
        "# Shape (3, 4)\n",
        "W1 = np.array([\n",
        "    [ 2.5, -1.2,  0.8,  3.1],  # Weights from x1\n",
        "    [-0.5,  2.8, -1.5,  0.3],  # Weights from x2\n",
        "    [ 1.7, -0.9,  2.3, -1.8]   # Weights from x3\n",
        "])"
      ],
      "metadata": {
        "id": "76PWD_H9N_OI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b1: Biases for hidden layer (4 neurons)\n",
        "# Shape (1, 4)\n",
        "b1 = np.array([[0.5, -0.3, 0.2, 0.7]])"
      ],
      "metadata": {
        "id": "DI4876q5OmQl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# W2: Weights from hidden (4 neurons) to output (2 classes)\n",
        "# Shape (4, 2)\n",
        "W2 = np.array([\n",
        "    [ 1.5, -2.3],  # Weights from h1\n",
        "    [-0.8,  1.9],  # Weights from h2\n",
        "    [ 2.1, -0.6],  # Weights from h3\n",
        "    [-1.3,  2.7]   # Weights from h4\n",
        "])"
      ],
      "metadata": {
        "id": "ofQJ1ClyOzpf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b2: Biases for output layer (2 classes)\n",
        "# Shape (1, 2)\n",
        "b2 = np.array([[0.3, -0.5]])"
      ],
      "metadata": {
        "id": "qE-IseFgO10X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x: Input sample\n",
        "# Shape (1, 3)\n",
        "x = np.array([[1.0, 0.5, 2.0]])"
      ],
      "metadata": {
        "id": "hL6URKzOO37F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_true: True label (Class 0: Sick)\n",
        "# Shape (1, 2)\n",
        "y_true = np.array([[1.0, 0.0]])"
      ],
      "metadata": {
        "id": "Fd9HqYifO5xI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A"
      ],
      "metadata": {
        "id": "OzVAz83zTpaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate hidden layer linear combination (z = x * W1 + b1)\n",
        "# (1, 3) @ (3, 4) -> (1, 4)\n",
        "z = np.dot(x, W1) + b1"
      ],
      "metadata": {
        "id": "J9Semy5ePBKN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOecDu6QPPk1",
        "outputId": "bdedd807-a71b-4f4a-9050-ac62ebf93b77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.15, -1.9 ,  4.85,  0.35]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    \"\"\"ReLU activation function.\"\"\"\n",
        "    return np.maximum(0, x)"
      ],
      "metadata": {
        "id": "bGoYnoOyPTod"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = relu(z)"
      ],
      "metadata": {
        "id": "VKiRF7-sPjSs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTEQODtYPm0X",
        "outputId": "37450699-ff68-4201-9d8a-2b4ae684c1bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.15, 0.  , 4.85, 0.35]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate output layer linear combination (z2 = h * W2 + b2)\n",
        "# (1, 4) @ (4, 2) -> (1, 2)\n",
        "z2 = np.dot(h, W2) + b2"
      ],
      "metadata": {
        "id": "NyUXxTpHPnpT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ThsXClAQDNt",
        "outputId": "e3bcdd59-ec35-428a-b946-26a052ca5209"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 19.255, -16.61 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Softmax activation function.\"\"\"\n",
        "    # Subtract max for numerical stability\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "metadata": {
        "id": "QKIkA0NTQGtL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate final output (y_hat = softmax(z2))\n",
        "# (1, 2)\n",
        "y_hat = softmax(z2)"
      ],
      "metadata": {
        "id": "fzcAALlyRGoI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY03-UI6RKcu",
        "outputId": "be89fc52-b395-4266-c1b1-6bf1c63d4513"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    \"\"\"Calculates the categorical cross-entropy loss.\"\"\"\n",
        "    # Add a small epsilon to avoid log(0)\n",
        "    epsilon = 1e-9\n",
        "    # Clip predictions to avoid extreme values\n",
        "    y_pred_clipped = np.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = -np.sum(y_true * np.log(y_pred_clipped))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "FKufkGOGRLss"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_data = cross_entropy_loss(y_true, y_hat)"
      ],
      "metadata": {
        "id": "3wnyWhF2R4VW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{L_data:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YpD4a0dSEQn",
        "outputId": "2d0dfe71-7f48-4aee-f0b2-531f0a0bd08d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B"
      ],
      "metadata": {
        "id": "no9y5ZxUThWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Idea A: L2 Regularization (Weight Decay): L_new = L_data + 0.01 * Σ(w^2)\n",
        "lambda_l2 = 0.01\n",
        "\n",
        "# Calculate L2 penalty term\n",
        "# Sum of squares of all weights in W1 and W2\n",
        "penalty_l2_W1 = np.sum(np.square(W1))\n",
        "penalty_l2_W2 = np.sum(np.square(W2))\n",
        "total_penalty_l2_term = penalty_l2_W1 + penalty_l2_W2\n",
        "total_penalty_l2 = lambda_l2 * total_penalty_l2_term"
      ],
      "metadata": {
        "id": "Nzs6plsrSFwu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_penalty_l2_term"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1vNuA2MUpSI",
        "outputId": "83f48a87-e928-4309-bcef-2529af164170"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(66.14)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_penalty_l2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NMJ73q-UAM9",
        "outputId": "303bd6e0-f0d6-474a-862b-8742b35a1237"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.6614)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L_new_l2 = L_data + total_penalty_l2"
      ],
      "metadata": {
        "id": "LeISXZoPUB_j"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_new_l2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEX35XtIUHUn",
        "outputId": "1ea2948e-bceb-467e-a70c-9127c2197a82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.661400001)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Idea B: L1 Regularization (Lasso): L_new = L_data + 0.005 * Σ|w| ---\")\n",
        "lambda_l1 = 0.005"
      ],
      "metadata": {
        "id": "f7MZhM2EUIa9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate L1 penalty term\n",
        "# Sum of absolute values of all weights in W1 and W2\n",
        "penalty_l1_W1 = np.sum(np.abs(W1))\n",
        "penalty_l1_W2 = np.sum(np.abs(W2))\n",
        "total_penalty_l1_term = penalty_l1_W1 + penalty_l1_W2\n",
        "total_penalty_l1 = lambda_l1 * total_penalty_l1_term"
      ],
      "metadata": {
        "id": "N_XWuYxkVX5F"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_penalty_l1_term"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg7YPHNCVcUe",
        "outputId": "52ba5636-1a94-4825-ed7b-71051cbcd52d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(32.599999999999994)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_penalty_l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgc7IvByVdtw",
        "outputId": "d32e500e-a02c-43ee-8b72-28f5c6d785c8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.16299999999999998)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total loss with L1\n",
        "L_new_l1 = L_data + total_penalty_l1"
      ],
      "metadata": {
        "id": "c_QpTIAfVets"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_new_l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdBA5F_pVq4F",
        "outputId": "b8c08f62-a0f3-4216-aa03-7bc0adf4ffa9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.16300000099999995)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total gradient for W2[0,0]\n",
        "# W2[0,0] corresponds to W2[0, 0] in numpy (value is 1.5)\n",
        "grad_L_data_wrt_W2_0_0 = -0.3\n",
        "W2_0_0 = W2[0, 0]\n",
        "\n",
        "# Gradient of L2 penalty: d/dw (lambda * w^2) = 2 * lambda * w\n",
        "grad_L2_penalty_wrt_W2_0_0 = 2 * lambda_l2 * W2_0_0\n",
        "print(f\"Gradient of L2 penalty w.r.t W2[0,0]: 2 * {lambda_l2} * {W2_0_0} = {grad_L2_penalty_wrt_W2_0_0:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW45QLxKVr5V",
        "outputId": "a8e37514-74bd-4291-afbf-a1325c3460a9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of L2 penalty w.r.t W2[0,0]: 2 * 0.01 * 1.5 = 0.030000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total gradient = gradient from data + gradient from penalty\n",
        "grad_total_l2 = grad_L_data_wrt_W2_0_0 + grad_L2_penalty_wrt_W2_0_0\n",
        "print(f\"Total Gradient (L2) for W2[0,0]: {grad_L_data_wrt_W2_0_0} + {grad_L2_penalty_wrt_W2_0_0:.6f} = {grad_total_l2:.6f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSaNZafeZox6",
        "outputId": "095dae88-4d9c-4492-ddee-3ae3f90559c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Gradient (L2) for W2[0,0]: -0.3 + 0.030000 = -0.270000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total gradient for W2[0,0]\n",
        "# Gradient of L1 penalty: d/dw (lambda * |w|) = lambda * sign(w)\n",
        "# sign(1.5) is 1\n",
        "grad_L1_penalty_wrt_W2_0_0 = lambda_l1 * np.sign(W2_0_0)\n",
        "print(f\"Gradient of L1 penalty w.r.t W2[0,0]: {lambda_l1} * sign({W2_0_0}) = {grad_L1_penalty_wrt_W2_0_0:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQYT0RUXZqaF",
        "outputId": "1648b335-4062-4680-ef95-3b67b7395c76"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of L1 penalty w.r.t W2[0,0]: 0.005 * sign(1.5) = 0.005000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total gradient = gradient from data + gradient from penalty\n",
        "grad_total_l1 = grad_L_data_wrt_W2_0_0 + grad_L1_penalty_wrt_W2_0_0\n",
        "print(f\"Total Gradient (L1) for W2[0,0]: {grad_L_data_wrt_W2_0_0} + {grad_L1_penalty_wrt_W2_0_0:.6f} = {grad_total_l1:.6f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXvHtkNPb1hQ",
        "outputId": "1ace29c4-4a43-49a6-c085-cb3f03ca077e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Gradient (L1) for W2[0,0]: -0.3 + 0.005000 = -0.295000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}